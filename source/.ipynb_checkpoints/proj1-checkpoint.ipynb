{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "from implementations import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 138.47 ,   51.655,   97.827, ...,    1.24 ,   -2.475,  113.497],\n",
       "       [ 160.937,   68.768,  103.235, ..., -999.   , -999.   ,   46.226],\n",
       "       [-999.   ,  162.172,  125.953, ..., -999.   , -999.   ,   44.251],\n",
       "       ...,\n",
       "       [ 105.457,   60.526,   75.839, ..., -999.   , -999.   ,   41.992],\n",
       "       [  94.951,   19.362,   68.812, ..., -999.   , -999.   ,    0.   ],\n",
       "       [-999.   ,   72.756,   70.831, ..., -999.   , -999.   ,    0.   ]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "path = '../data/train.csv'\n",
    "\n",
    "y, tx,ids = load_csv_data(path)\n",
    "tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As some column as -999 values, we have to replace them \n",
    "# first try : use the mean of each column to replace them : 0.741 with ridge lambda = 2\n",
    "# second try : use the median of each column to replace them 0.742 with ridge lambda = 2\n",
    "# adapted code from :https://stackoverflow.com/questions/18689235/numpy-array-replace-nan-values-with-average-of-columns\n",
    "tx[tx==-999]=np.nan\n",
    "col_median = np.nanmedian(tx,axis = 0) #change median by mean if you want mean\n",
    "indices = np.where(np.isnan(tx))\n",
    "tx[indices]=np.take(col_median,indices[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.38470e+02,  5.16550e+01,  9.78270e+01, ...,  1.24000e+00,\n",
       "        -2.47500e+00,  1.13497e+02],\n",
       "       [ 1.60937e+02,  6.87680e+01,  1.03235e+02, ..., -1.00000e-02,\n",
       "        -2.00000e-03,  4.62260e+01],\n",
       "       [ 1.12406e+02,  1.62172e+02,  1.25953e+02, ..., -1.00000e-02,\n",
       "        -2.00000e-03,  4.42510e+01],\n",
       "       ...,\n",
       "       [ 1.05457e+02,  6.05260e+01,  7.58390e+01, ..., -1.00000e-02,\n",
       "        -2.00000e-03,  4.19920e+01],\n",
       "       [ 9.49510e+01,  1.93620e+01,  6.88120e+01, ..., -1.00000e-02,\n",
       "        -2.00000e-03,  0.00000e+00],\n",
       "       [ 1.12406e+02,  7.27560e+01,  7.08310e+01, ..., -1.00000e-02,\n",
       "        -2.00000e-03,  0.00000e+00]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definitions of the hyperparameters\n",
    "max_iters = 200\n",
    "gamma = 0.000006\n",
    "initial_w = np.zeros(tx.shape[1])\n",
    "lambda_ = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model\n",
    "w_ls, loss_ls = least_squares(y,tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_lsGD,loss_lsGD = least_squares_GD(y, tx, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_lsSGD,loss_lsSGD = least_squares_SGD(y, tx, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ridge,loss_ridge = ridge_regression(y,tx,lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio, seed=1):\n",
    "    \"\"\"\n",
    "    split the dataset based on the split ratio. If ratio is 0.8 \n",
    "    you will have 80% of your data set dedicated to training \n",
    "    and the rest dedicated to testing\n",
    "    \"\"\"\n",
    "    # set seed random\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    num_row = len(y)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    index_split = int(np.floor(ratio * num_row))\n",
    "    index_tr = indices[: index_split]\n",
    "    index_te = indices[index_split:]\n",
    "    # create split\n",
    "    x_tr = x[index_tr]\n",
    "    x_te = x[index_te]\n",
    "    y_tr = y[index_tr]\n",
    "    y_te = y[index_te]\n",
    "    return x_tr, x_te, y_tr, y_te\n",
    "\n",
    "lambdas = [25,10,4,2,1.0,0.8,0.5,0.3,0.2,0.1,0.05,0.02,0.01,0.001]\n",
    "ratio = 0.8\n",
    "x_tr, x_te, y_tr, y_te=split_data(tx, y, ratio, seed=6)\n",
    "def grid_search(x_tr, x_te, y_tr, y_te,lambdas,ratio):\n",
    "    \n",
    "    rmse_tr = []\n",
    "    rmse_te = []\n",
    "    for ind, lambda_ in enumerate(lambdas):\n",
    "        weight,_ = ridge_regression(y_tr, x_tr, lambda_)\n",
    "        rmse_tr.append(compute_mse(y_tr, x_tr, weight))\n",
    "        rmse_te.append(compute_mse(y_te, x_te, weight))\n",
    "        print(\"proportion={p}, lambda={l:.3f}, Training RMSE={tr:.15f}, Testing RMSE={te:.15f}\".format(\n",
    "               p=ratio, l=lambda_, tr=rmse_tr[ind], te=rmse_te[ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion=0.8, lambda=25.000, Training RMSE=0.000001718932766, Testing RMSE=0.000006899107575\n",
      "proportion=0.8, lambda=10.000, Training RMSE=0.000001718932550, Testing RMSE=0.000006899086932\n",
      "proportion=0.8, lambda=4.000, Training RMSE=0.000001718932466, Testing RMSE=0.000006899078938\n",
      "proportion=0.8, lambda=2.000, Training RMSE=0.000001718932374, Testing RMSE=0.000006899076452\n",
      "proportion=0.8, lambda=1.000, Training RMSE=0.000001718932201, Testing RMSE=0.000006899075507\n",
      "proportion=0.8, lambda=0.800, Training RMSE=0.000001718932116, Testing RMSE=0.000006899075436\n",
      "proportion=0.8, lambda=0.500, Training RMSE=0.000001718931868, Testing RMSE=0.000006899075621\n",
      "proportion=0.8, lambda=0.300, Training RMSE=0.000001718931446, Testing RMSE=0.000006899076391\n",
      "proportion=0.8, lambda=0.200, Training RMSE=0.000001718930952, Testing RMSE=0.000006899077541\n",
      "proportion=0.8, lambda=0.100, Training RMSE=0.000001718929659, Testing RMSE=0.000006899081160\n",
      "proportion=0.8, lambda=0.050, Training RMSE=0.000001718927711, Testing RMSE=0.000006899088057\n",
      "proportion=0.8, lambda=0.020, Training RMSE=0.000001718924569, Testing RMSE=0.000006899104513\n",
      "proportion=0.8, lambda=0.010, Training RMSE=0.000001718922596, Testing RMSE=0.000006899121768\n",
      "proportion=0.8, lambda=0.001, Training RMSE=0.000001718920747, Testing RMSE=0.000006899163812\n"
     ]
    }
   ],
   "source": [
    "grid_search(x_tr, x_te, y_tr, y_te,lambdas,ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "y_test, tx_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "# Have to apply the same data cleaning as for train set\n",
    "tx_test[tx_test==-999]=np.nan\n",
    "col_median = np.nanmedian(tx_test,axis = 0)#change median by mean if you want mean\n",
    "indices = np.where(np.isnan(tx_test))\n",
    "tx_test[indices]=np.take(col_median,indices[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/result.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(w_lsGD, tx_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8351729380998807"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28300692401710836"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
